# 多变量线性回归(Linear Regression with Multiple Variables)
## 1、多维特征
![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/multivar.png?raw=true)
## 2、复合函数求导
![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/dx.png?raw=true)
## 3、多变量梯度下降
![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/multigradient.png?raw=true)
## 4、特征缩放与学习率
面对多维特征的时候，我们要保证这些特征都具有相近的尺度，**这样可以帮助梯度下降算法更快的收敛**

![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/featuremin.png?raw=true)

梯度下降算法的每次迭代受到学习率的影响，**如果学习率𝑎过小，则达到收敛所需的迭代次数会非常高；如果学习率𝑎过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。**  

通常可以考虑尝试些学习率：𝛼 = 0.01，0.03，0.1，0.3，1，3，10

## 5、正规方程
正规方程求解公式：

![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/xq.png?raw=true)

![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/X.png?raw=true)

推导过程：https://blog.csdn.net/weixin_39449570/article/details/78520543


