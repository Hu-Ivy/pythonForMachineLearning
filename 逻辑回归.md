# 逻辑回归(Logistic Regression 分类)
## 一、逻辑回归理论基础
关于逻辑回归问题的算法分析，在![机器学习笔记四--逻辑回归](https://github.com/daacheng/pythonForMachineLearning/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%9B--%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.md)中已经写的很详细了。**主要是介绍了逻辑回归算法的“假设函数”，“代价函数”，“梯度下降算法求导公式”。**

**这里主要介绍是结合实际情景，用python实现以下三个函数，逻辑回归算法的“假设函数”，“代价函数”，及“梯度下降算法”，用“梯度下降算法”求得最优参数，对实际数据进行分类。**

![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/logisticfunc.png?raw=true)  

![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/costlogis.png?raw=true)  

![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/daoshulogis.png?raw=true)  

## 二、Python实现逻辑回归算法
### 数据集信息
训练集部分数据结构如下所示，两个特征x1,x2.分成两类0或1.第一步要做的就是读取txt文件里的训练数据，构建特征矩阵X,标签矩阵y.

    x1               x2             y
    -0.017612	14.053064	0
    -1.395634	4.662541	1
    -0.752157	6.538620	0
    -1.322371	7.152853	0
    0.423363	11.054677	0
    0.406704	7.067335	1

