# 逻辑回归(Logistic Regression 分类)
## 一、逻辑回归理论基础
关于逻辑回归问题的算法分析，在![机器学习笔记四--逻辑回归](https://github.com/daacheng/pythonForMachineLearning/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%9B--%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.md)中已经写的很详细了。**主要是介绍了逻辑回归算法的“假设函数”，“代价函数”，“梯度下降算法求导公式”。**

**这里主要介绍是结合实际情景，用python实现以下三个函数，逻辑回归算法的“假设函数”，“代价函数”，及“梯度下降算法”，用“梯度下降算法”求得最优参数，对实际数据进行分类。**

![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/logisticfunc.png?raw=true)  

![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/costlogis.png?raw=true)  

![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/daoshulogis.png?raw=true)  

## 二、Python实现逻辑回归算法
### 2.1、数据集信息
**训练集部分数据结构如下所示，两个特征x1,x2.分成两类0或1.第一步要做的就是读取txt文件里的训练数据，构建特征矩阵X,标签矩阵y.**

    x1               x2             y
    -0.017612	14.053064	0
    -1.395634	4.662541	1
    -0.752157	6.538620	0
    -1.322371	7.152853	0
    0.423363	11.054677	0
    0.406704	7.067335	1

### 2.2、矩阵运算
**逻辑回归问题的三个方程,利用矩阵计算很方便，这里指介绍一下矩阵运算求假设函数值**
![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/juzhen.png?raw=true)

### 2.3、代码实现

        %matplotlib inline
        import matplotlib
        import matplotlib.pyplot as plt
        import csv
        import numpy as np
        import math

        def loadDataset():
            data=[]
            labels=[]
            with open('logisticDataset.txt','r') as f:
                reader = csv.reader(f,delimiter='\t')
                for row in reader:
                    data.append([1.0, float(row[0]), float(row[1])])
                    labels.append(int(row[2]))
            return data,labels

        def plotBestFit(W):
            # 把训练集数据用坐标的形式画出来
            dataMat,labelMat=loadDataset()
            dataArr = np.array(dataMat)
            n = np.shape(dataArr)[0] 
            xcord1 = []
            ycord1 = []
            xcord2 = []
            ycord2 = []
            for i in range(n):
                if int(labelMat[i])== 1:
                    xcord1.append(dataArr[i,1]); ycord1.append(dataArr[i,2])
                else:
                    xcord2.append(dataArr[i,1]); ycord2.append(dataArr[i,2])
            fig = plt.figure()
            ax = fig.add_subplot(111)
            ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')
            ax.scatter(xcord2, ycord2, s=30, c='green')

            # 把分类边界画出来
            x = np.arange(-3.0,3.0,0.1)
            y = (-W[0]-W[1]*x)/W[2]
            ax.plot(x,y)
            plt.show()

        def plotloss(loss_list):
            x = np.arange(0,30,0.01)
            plt.plot(x,np.array(loss_list),label = 'linear')

            plt.xlabel('time')       # 梯度下降的次数
            plt.ylabel('loss')       # 损失值
            plt.title('loss trend')         # 损失值随着W不断更新，不断变化的趋势
            plt.legend()               # 图形图例
            plt.show()



        def main():
            # 读取训练集(txt文件)中的数据,
            data, labels = loadDataset()
            # 将数据转换成矩阵的形式，便于后面进行计算
            # 构建特征矩阵X
            X = np.array(data)
            # 构建标签矩阵y
            y = np.array(labels).reshape(-1,1)
            # 随机生成一个w参数(权重)矩阵    .reshape((-1,1))的作用是，不知道有多少行，只想变成一列
            W = 0.001*np.random.randn(3,1).reshape((-1,1))   
            # m表示一共有多少组训练数据
            m = len(X)
            # 定义梯度下降的学习率 0.03
            learn_rate = 0.03

            loss_list = []
            # 实现梯度下降算法，不断更新W,获得最优解，使损失函数的损失值最小
            for i in range(3000):
                # 最重要的就是这里用numpy 矩阵计算，完成假设函数计算，损失函数计算，梯度下降计算
                # 计算假设函数 h(w)x
                g_x = np.dot(X,W)
                h_x = 1/(1+np.exp(-g_x))

                # 计算损失函数 Cost Function 的损失值loss
                loss = np.log(h_x)*y+(1-y)*np.log(1-h_x)
                loss = -np.sum(loss)/m
                loss_list.append(loss)

                # 梯度下降函数更新W权重
                dW = X.T.dot(h_x-y)/m
                W += -learn_rate*dW

            # 得到更新后的W，可视化
            print('W最优解:')
            print(W)
            print('最终得到的分类边界:')
            plotBestFit(W)
            print('损失值随着W不断更新，不断变化的趋势:')
            plotloss(loss_list)



            # 定义一个测试数据，计算他属于那一类别
            test_x = np.array([1,-1.395634,4.662541])
            test_y = 1/(1+np.exp(-np.dot(test_x,W)))
            print(test_y)

        #     print(data_arr)
        if __name__=='__main__':
            main()
            

### 2.4、结果可视化

![](https://github.com/daacheng/pythonForMachineLearning/blob/master/pic/reslogistic.png?raw=true)
